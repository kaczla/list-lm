- [minbpe](https://github.com/karpathy/minbpe) - Minimal, clean code for the (byte-level) Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization.
- [SentencePiece](https://github.com/google/sentencepiece) - SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) and unigram language model ) with the extension of direct training from raw sentences.
- [StochasTok](https://arxiv.org/abs/2506.01687) - Stochastic tokenization scheme that randomly splits tokens during training to improve fine-grained subword understanding in LLMs.
- [tiktoken](https://github.com/openai/tiktoken) - tiktoken is a fast BPE tokeniser for use with OpenAI's models.
- [tokenizers](https://github.com/huggingface/tokenizers) - Provides an implementation of today's most used tokenizers, with a focus on performance and versatility.
- [TokenMonster](https://github.com/alasdairforsythe/tokenmonster) - TokenMonster is an ungreedy subword tokenizer and vocabulary generator, enabling language models to run faster, cheaper, smarter and generate longer streams of text.
- [transtokenizers](https://github.com/lagom-nlp/transtokenizer) - transtokenizers is a token translation for language models
